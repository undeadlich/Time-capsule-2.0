{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: CPU\n",
      "\n",
      "Checking for new/changed images...\n",
      "\n",
      "Image retrieval ready! (type 'exit' to quit)\n",
      "No matches found!\n",
      "No matches found!\n"
     ]
    }
   ],
   "source": [
    "# image_caption_retrieval.py\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from numpy.linalg import norm\n",
    "from PIL import Image\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Configuration\n",
    "IMAGE_DIR = \"images\"\n",
    "MODELS_DIR = \"models\"\n",
    "DB_FILE = os.path.join(MODELS_DIR, \"image_database.pkl\")\n",
    "MIN_CONFIDENCE = 0.4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MAX_COLS = 5  # Maximum images per row\n",
    "\n",
    "class ImageRetrievalSystem:\n",
    "    def __init__(self):\n",
    "        self.processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\", cache_dir=MODELS_DIR)\n",
    "        self.caption_model = BlipForConditionalGeneration.from_pretrained(\n",
    "            \"Salesforce/blip-image-captioning-base\", \n",
    "            cache_dir=MODELS_DIR\n",
    "        ).to(DEVICE)\n",
    "        self.embedder = SentenceTransformer(\n",
    "            \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "            cache_folder=MODELS_DIR\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "        # Load existing database\n",
    "        self.database = self.load_database()\n",
    "        \n",
    "    def load_database(self):\n",
    "        \"\"\"Load processed images from previous sessions\"\"\"\n",
    "        if os.path.exists(DB_FILE):\n",
    "            with open(DB_FILE, \"rb\") as f:\n",
    "                db = pickle.load(f)\n",
    "                print(f\"Loaded {len(db)} existing image records\")\n",
    "                return self.validate_database(db)\n",
    "        return []\n",
    "\n",
    "    def save_database(self):\n",
    "        \"\"\"Save current state to disk\"\"\"\n",
    "        os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "        with open(DB_FILE, \"wb\") as f:\n",
    "            pickle.dump(self.database, f)\n",
    "            \n",
    "    def validate_database(self, db):\n",
    "        \"\"\"Remove entries for missing images or modified files\"\"\"\n",
    "        valid_entries = []\n",
    "        for entry in db:\n",
    "            if not os.path.exists(entry['path']):\n",
    "                continue\n",
    "            current_mtime = os.path.getmtime(entry['path'])\n",
    "            if current_mtime != entry['last_modified']:\n",
    "                continue\n",
    "            valid_entries.append(entry)\n",
    "        return valid_entries\n",
    "\n",
    "    def generate_caption(self, image_path):\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        inputs = self.processor(image, return_tensors=\"pt\").to(DEVICE)\n",
    "        output = self.caption_model.generate(**inputs)\n",
    "        return self.processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    def process_image(self, image_path):\n",
    "        \"\"\"Process image only if not already in database\"\"\"\n",
    "        current_mtime = os.path.getmtime(image_path)\n",
    "        \n",
    "        # Check if we already have this image\n",
    "        for entry in self.database:\n",
    "            if entry['path'] == image_path and entry['last_modified'] == current_mtime:\n",
    "                return\n",
    "            \n",
    "        # Process new/changed image\n",
    "        caption = self.generate_caption(image_path)\n",
    "        embedding = self.embedder.encode(caption, convert_to_tensor=True).cpu().numpy()\n",
    "        \n",
    "        # Update database\n",
    "        self.database.append({\n",
    "            \"path\": image_path,\n",
    "            \"caption\": caption,\n",
    "            \"embedding\": embedding,\n",
    "            \"last_modified\": current_mtime\n",
    "        })\n",
    "        print(f\"Processed: {image_path}\")\n",
    "\n",
    "    def search(self, text_query):\n",
    "        query_embedding = self.embedder.encode(text_query, convert_to_tensor=True).cpu().numpy()\n",
    "        results = []\n",
    "        \n",
    "        for item in self.database:\n",
    "            sim = np.dot(query_embedding, item[\"embedding\"]) / (\n",
    "                norm(query_embedding) * norm(item[\"embedding\"])\n",
    "            )\n",
    "            results.append({\n",
    "                \"path\": item[\"path\"],\n",
    "                \"caption\": item[\"caption\"],\n",
    "                \"confidence\": sim\n",
    "            })\n",
    "        \n",
    "        results.sort(key=lambda x: x[\"confidence\"], reverse=True)\n",
    "        return results\n",
    "\n",
    "def display_results(results, query, num_results):\n",
    "    valid_results = [r for r in results if r[\"confidence\"] >= MIN_CONFIDENCE][:num_results]\n",
    "    \n",
    "    if not valid_results:\n",
    "        print(f\"No images found with confidence â‰¥ {MIN_CONFIDENCE}\")\n",
    "        return\n",
    "\n",
    "    total_images = len(valid_results)\n",
    "    rows = (total_images + MAX_COLS - 1) // MAX_COLS  # Calculate rows needed\n",
    "    cols = min(MAX_COLS, total_images)\n",
    "    \n",
    "    plt.figure(figsize=(15, 3.5 * rows))\n",
    "    plt.suptitle(\n",
    "        f\"Found {total_images} results for: '{query}'\\n(Minimum confidence: {MIN_CONFIDENCE})\", \n",
    "        y=1.02 + (rows * 0.03), \n",
    "        fontsize=12\n",
    "    )\n",
    "    \n",
    "    for idx, result in enumerate(valid_results, 1):\n",
    "        plt.subplot(rows, cols, idx)\n",
    "        img = Image.open(result[\"path\"])\n",
    "        plt.imshow(img)\n",
    "        \n",
    "        # Truncate long captions for display\n",
    "        caption = result[\"caption\"] if len(result[\"caption\"]) <= 35 else f\"{result['caption'][:32]}...\"\n",
    "        \n",
    "        plt.title(\n",
    "            f\"Confidence: {result['confidence']:.2f}\\n{caption}\",\n",
    "            fontsize=9,\n",
    "            pad=2\n",
    "        )\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout(pad=1.5)\n",
    "    plt.show()\n",
    "\n",
    "def get_positive_integer(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            n = int(input(prompt))\n",
    "            if n > 0:\n",
    "                return n\n",
    "            print(\"Please enter a number greater than 0\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a whole number\")\n",
    "\n",
    "def main():\n",
    "    system = ImageRetrievalSystem()\n",
    "    \n",
    "    if not os.path.exists(IMAGE_DIR):\n",
    "        os.makedirs(IMAGE_DIR)\n",
    "        print(f\"Add images to '{IMAGE_DIR}' and restart\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nChecking for new/changed images...\")\n",
    "    new_files = 0\n",
    "    for fname in os.listdir(IMAGE_DIR):\n",
    "        if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            img_path = os.path.join(IMAGE_DIR, fname)\n",
    "            system.process_image(img_path)\n",
    "            new_files += 1\n",
    "            \n",
    "    if new_files > 0:\n",
    "        system.save_database()\n",
    "        print(f\"Processed {new_files} new/changed images\")\n",
    "\n",
    "    print(\"\\nImage retrieval ready! (type 'exit' to quit)\")\n",
    "    while True:\n",
    "        query = input(\"\\nSearch query: \").strip()\n",
    "        if query.lower() == \"exit\":\n",
    "            break\n",
    "            \n",
    "        results = system.search(query)\n",
    "        if not results:\n",
    "            print(\"No matches found!\")\n",
    "            continue\n",
    "            \n",
    "        num_images = get_positive_integer(\"How many images would you like to display? \")\n",
    "        display_results(results, query, num_images)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Running on device: {DEVICE.upper()}\")\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
